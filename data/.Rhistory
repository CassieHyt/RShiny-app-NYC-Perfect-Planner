scale = "none",
col = bluered(100), margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:trust)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T, main="Inaugural Speeches")
presid.summary=tbl_df(sentence.list)%>%
filter(type=="nomin", File%in%sel.comparison)%>%
#group_by(paste0(type, File))%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust)
#negative=mean(negative),
#positive=mean(positive)
)
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1], iter.max=200,
5)
fviz_cluster(km.res,
stand=F, repel= TRUE,
data = presid.summary[,-1], xlab="", xaxt="n",
show.clust.cent=FALSE)
corpus.list=sentence.list[2:(nrow(sentence.list)-1), ]
sentence.pre=sentence.list$sentences[1:(nrow(sentence.list)-2)]
sentence.post=sentence.list$sentences[3:(nrow(sentence.list)-1)]
corpus.list$snipets=paste(sentence.pre, corpus.list$sentences, sentence.post, sep=" ")
rm.rows=(1:nrow(corpus.list))[corpus.list$sent.id==1]
rm.rows=c(rm.rows, rm.rows-1, rm.rows-2,rm.rows-3,nrow(corpus.list),nrow(corpus.list)-1,nrow(corpus.list)-2)
corpus.list=corpus.list[-rm.rows, ]
docs <- Corpus(VectorSource(corpus.list$snipets))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
docs <-tm_map(docs,content_transformer(tolower))
docs <-tm_map(docs,content_transformer(tolower))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
docs <-tm_map(docs,content_transformer(tolower))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
docs <- tm_map(docs, removePunctuation)
docs <-tm_map(docs,content_transformer(tolower))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs,stemDocument)
dtm <- DocumentTermMatrix(docs)
#convert rownames to filenames#convert rownames to filenames
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm  <- dtm[rowTotals> 0, ]
corpus.list=corpus.list[rowTotals>0, ]
k <- 2
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
k <- 2
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
head(ldaOut)
ldaOut.topics <- as.matrix(topics(ldaOut))
head(ldaOut.topics)
table(c(1:k, ldaOut.topics))
tail(ldaOut.topics)
write.csv(ldaOut.topics,file=paste("../out/LDAGibbs",k,"DocsToTopics.csv"))
ldaOut.terms <- as.matrix(terms(ldaOut,6))
head(ldaOut.terms)
write.csv(ldaOut.terms,file=paste("../out/LDAGibbs",k,"TopicsToTerms.csv"))
topicProbabilities <- as.data.frame(ldaOut@gamma)
head(topicProbabilities)
write.csv(topicProbabilities,file=paste("../out/LDAGibbs",k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
head(terms.beta)
head(terms.beta,1)
terms.beta=ldaOut@beta
head(terms.beta)
head(ldaOut@gamma)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
topics.hash=c("Economy", "America")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]
colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
head(corpus.list$ldatopic)
tail(corpus.list$ldatopic)
ldaOut.topics
head(corpus.list$ldahash)
colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
par(mar=c(1,1,1,1))
topic.summary=tbl_df(corpus.list.df)%>%
filter(type%in%c("nomin", "inaug"), File%in%sel.comparison)%>%
select(File, Economy:America)%>%
group_by(File)%>%
summarise_each(funs(mean))
topic.summary=as.data.frame(topic.summary)
rownames(topic.summary)=topic.summary[,1]
head(topic.summary)
topic.plot=c(1, 13, 9, 11, 8, 3, 7)
print(topics.hash[topic.plot])
topic.plot=c(1,2)
print(topics.hash[topic.plot])
heatmap.2(as.matrix(topic.summary[,topic.plot+1]),
scale = "column", key=F,
col = bluered(100),
cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
trace = "none", density.info = "none")
heatmap.2(as.matrix(topic.summary[,topic.plot+1]),
scale = "column", key=F,
col = bluered(100),
cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
trace = "none", density.info = "none")
heatmap.2(as.matrix(topic.summary[,topic.plot+1]),
scale = "column", key=F,
col = bluered(100),
cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
trace = "none", density.info = "none")
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
topic.plot=c(1,2)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="nomin",Term==1)%>%select(sent.id, Economy:America)
speech.df=as.matrix(speech.df)
head(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Nomination")
f.smooth.topic()
f.smooth.topic
head(speech.df[,-1])
f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Nomination")
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
speech.df=tbl_df(corpus.list.df)%>%filter(type=="nomin", word.count<20)%>%select(sentences, Economy:America)
names(speech.df)
colnames(speech.df)
as.character(speech.df$sentences[apply(as.data.frame(speech.df[,-1]), 2, which.max)])
names(speech.df)[-1]
presid.summary=tbl_df(corpus.list.df)%>%
filter(type=="inaug", File%in%sel.comparison)%>%
select(File, Economy:America)%>%
group_by(File)%>%
summarise_each(funs(mean))
presid.summary=as.data.frame(presid.summary)
head(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(scale(presid.summary[,-1]), iter.max=200,
5)
fviz_cluster(km.res,
stand=T, repel= TRUE,
data = presid.summary[,-1],
show.clust.cent=FALSE)
fviz_cluster(km.res,
stand=T, repel= TRUE,
data = presid.summary[,-1],
show.clust.cent=FALSE)
library("xlsx")
library("rvest")
library("magrittr")
library("dplyr")
library("readr")
library("tidytext")
library("tm")
library("ggplot2")
library("wordcloud")
library("RColorBrewer")
library("qdap")
library("syuzhet")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
### Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches.
inaug=f.speechlinks(main.page)
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
inaug.list$type=rep("inaug", nrow(inaug.list))
inaug.list=cbind(inaug.list, inaug)
inaug.list$fulltext=NA
for(i in seq(nrow(inaug.list))) {
text <- read_html(inaug.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
inaug.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/fulltext/",
inaug.list$type[i],
inaug.list$File[i], "-",
inaug.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
education<-read.xlsx("../data/education.xlsx",sheetIndex = 1,header=T)
law<-read.xlsx("../data/Law.xlsx",sheetIndex = 1,header = T)
df1<-merge(inaug.list,education,by="President",all=F)
df<-merge(df1,law,by="President",all=T)
df<-df[,c(1,6,11,13,14)]
df$id<-c(1:nrow(df))
mean(df$Words)
df$President[which.max(df$Words)]
ggplot(df,aes(x=id,y=Words,color=as.numeric(is.na(df$School)==F),group=is.na(df$School)))+geom_point(alpha=0.8)+geom_smooth(alpha=.5, size=1)
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all)
tdm.tidy=tidy(tdm.all)
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
x=c(1:20)
x
y=0.028+0.00042*x+1
y
y[1]*y[2]*y[3]*y[4]*y[5]*y[6]*y[7]*y[8]*y[9]*y[10]*y[11]*y[12]*y[13]*y[14]*y[15]*y[16]*y[17]*y[18]*y[19]*y[20]
1.892431^{1/20}
1.032407-1
mean(y)
mean(y[1:15])
1000/(e^{15*0.03136})
1000/(exp{15*0.03136})
1000/(exp(15*0.03136))
sum(y[1:15])
1000*exp(-15.4704)
x=c(1:20)
y=0.028+0.00042*x
mean(y[1:15])
sum(y[1:15])
1000*exp(- 0.4704)
0.028*15-0.5*0.00042*15*15
exp(- 0.37275)
price = 888.489
C = 21
T= 2
par = 1000
r = c(0.02,0.022,0.027,0.03)
value = bondvalue(C, T, r, par)
bondvalue = function(c, T, r, par)
{
#       Computes bv = bond values (current prices) corresponding
#       to all values of yield to maturity in the
#       input vector r
#
# INPUT
#        c = coupon payment (semiannual)
#        T = time to maturity (in years)
#        r = vector of yields to maturity (semiannual rates)
#        par = par value
#
bv = c / r + (par - c / r) * (1 + r)^(-2 * T)
bv
}
value = bondvalue(C, T, r, par)
yield2M = spline(value, r, xout = price) # spline interpolation
plot(r, value, xlab = ’yield to maturity’, ylab = ’price of bond’,
type = "l",  lwd = 2)
plot(r, value, xlab = 'yield to maturity', ylab = 'price of bond',
type = "l",lwd = 2)
abline(h = 1200)
abline(v = yield2M)
value
yield2M
price = 967.23
value = bondvalue(C, T, r, par)
yield2M = spline(value, r, xout = price) # spline interpolation
yield2M
exp(-15*0.03115)
x<-sample(c(0,5), 100)
x<-sample(c(0,5), 100, replace = TRUE)
x
x<-sample(c(0:5), 100, replace = TRUE)
x
x<-sample(c(0:4), 100, replace = TRUE)
y<-x/4
plot(x,y)
plot(x,y,type=l)
plot(x,y,type="L")
plot(x,y,type="l")
x<-sample(c(0:4), 100, replace = TRUE)
x
qunif(4)
qunif(x,min=0,max=4)
punif(x,min=0,max=4)
x<-sample(c(-1:5), 100, replace = TRUE)
x
y<-punif(x,min=0,max=4)
plot(y~x)
plot(y~x,type="l")
lm(y~x)
line(y~x)
plot(y~x)
abline(y~x)
plot(y~x,type="l")
plot(y~x,type="b")
plot(y~x,type="1")
plot(y~x,type="s")
line(y~x)
abline(y~x)
lines(y~x)
lines(y~x)
plot(y~x)
lines(y~x)
sort(x)
x<-sample(c(-1:5), 100, replace = TRUE)
x<-sort(x)
y<-punif(x,min=0,max=4)
y<-sort(y)
plot(y~x)
plot(y~x,type="l")
plot(y~x,type="l",main="Cumulative Distribution Function",ylab="F(x)")
setwd("~/Desktop/5243 ADS/proj2/Spr2017-proj2-grp14/data")
theater<-read.csv("theater.csv",header=T)
View(theater)
library(shiny)
library(leaflet)
install.packages("leaflet")
library(leaflet)
m <- leaflet(data=theater)
m<- addTiles(m)
addMarkers(m,lng=~longitude,lat=~latitude)
addMarkers(m,lng=~LON,lat=~LAT)
library(shiny)
library(leaflet)
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
runApp('~/Desktop/5243 ADS/proj2/App-1')
